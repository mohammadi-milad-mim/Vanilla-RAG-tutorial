{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ9sqO0Pw2pG"
      },
      "source": [
        "# LanceDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BsO70C8xAj-"
      },
      "source": [
        "## 1. Quick Start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqdJ09DOuyz9"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx-pvhwwu37D",
        "outputId": "09a4b38d-0dfa-48fd-c019-efb9cfd515f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lancedb in ./.venv/lib/python3.11/site-packages (0.17.0)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.3)\n",
            "Requirement already satisfied: sentence_transformers in ./.venv/lib/python3.11/site-packages (3.3.1)\n",
            "Requirement already satisfied: deprecation in ./.venv/lib/python3.11/site-packages (from lancedb) (2.1.0)\n",
            "Requirement already satisfied: pylance==0.20.0 in ./.venv/lib/python3.11/site-packages (from lancedb) (0.20.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in ./.venv/lib/python3.11/site-packages (from lancedb) (4.67.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in ./.venv/lib/python3.11/site-packages (from lancedb) (2.10.4)\n",
            "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from lancedb) (24.2)\n",
            "Requirement already satisfied: overrides>=0.7 in ./.venv/lib/python3.11/site-packages (from lancedb) (7.7.0)\n",
            "Requirement already satisfied: pyarrow>=14 in ./.venv/lib/python3.11/site-packages (from pylance==0.20.0->lancedb) (18.1.0)\n",
            "Requirement already satisfied: numpy>=1.22 in ./.venv/lib/python3.11/site-packages (from pylance==0.20.0->lancedb) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic>=1.10->lancedb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.11/site-packages (from pydantic>=1.10->lancedb) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install lancedb pandas sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYslTCJ3vHtX"
      },
      "source": [
        "### Connect to a database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C3luLyg5vYQA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/miladmohammadi/Documents/Semester-3/TAs/IIR Workshop/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import lancedb\n",
        "\n",
        "#path\n",
        "uri = \"data/sample-lancedb\"\n",
        "\n",
        "db = lancedb.connect(uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iI2bPq8vujQ"
      },
      "source": [
        "### Create a table from initial data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pgjMS-WhvyFt"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    {\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n",
        "    {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0},\n",
        "    {\"vector\": [10, 13], \"item\": \"fizz\", \"price\":1}\n",
        "]\n",
        "\n",
        "tbl = db.create_table(\"my_table\", data=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBTEVBTKwOAL"
      },
      "source": [
        "#### from pandas DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2wL9eZRKwWgw"
      },
      "outputs": [],
      "source": [
        "#If running local you may need to change the max recursion limit\n",
        "import sys\n",
        "sys.setrecursionlimit(10000)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    [\n",
        "        {\"vector\": [3.1, 4.1], \"item\": \"foo\", \"price\": 10.0},\n",
        "        {\"vector\": [5.9, 26.5], \"item\": \"bar\", \"price\": 20.0},\n",
        "        {\"vector\": [10, 13], \"item\": \"fizz\", \"price\":1}\n",
        "    ]\n",
        ")\n",
        "\n",
        "tbl = db.create_table(\"my_table\", data=df, mode=\"overwrite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAMqaKUrxOPP"
      },
      "source": [
        "### Create an empty table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mOvtKANZxaZX"
      },
      "outputs": [],
      "source": [
        "# Define Schema\n",
        "from lancedb.pydantic import Vector, LanceModel\n",
        "\n",
        "class DataSchema(LanceModel):\n",
        "    vector: Vector(2)\n",
        "    item: str\n",
        "    price: float\n",
        "\n",
        "\n",
        "tbl = db.create_table(\"empty_table\", schema=DataSchema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcnxG1YGyZ17"
      },
      "source": [
        "### Add data to a table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IDgnedPkydiA"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    {\"vector\": [1, 1], \"item\": \"tar\", \"price\": 100.0},\n",
        "    {\"vector\": [7, 7], \"item\": \"jar\", \"price\": 200.0},\n",
        "]\n",
        "\n",
        "tbl.add(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "jo1uQ-1252H7",
        "outputId": "46540869-42ca-46dc-e179-31098818e057"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vector</th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1.0, 1.0]</td>\n",
              "      <td>tar</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[7.0, 7.0]</td>\n",
              "      <td>jar</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       vector item  price\n",
              "0  [1.0, 1.0]  tar  100.0\n",
              "1  [7.0, 7.0]  jar  200.0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hKt6juP7zJX"
      },
      "source": [
        "#### Add data in batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BW-z9vTo8H3D"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(\n",
        "    [\n",
        "        {\"vector\": [12.34, 56.78], \"item\": \"Chair\", \"price\": 49.99},\n",
        "        {\"vector\": [23.45, 67.89], \"item\": \"Table\", \"price\": 89.99},\n",
        "        {\"vector\": [34.56, 78.90], \"item\": \"Lamp\", \"price\": 29.99},\n",
        "        {\"vector\": [45.67, 89.01], \"item\": \"Sofa\", \"price\": 299.99},\n",
        "        {\"vector\": [56.78, 90.12], \"item\": \"Desk\", \"price\": 149.99},\n",
        "        {\"vector\": [67.89, 12.34], \"item\": \"Bed\", \"price\": 399.99},\n",
        "        {\"vector\": [78.90, 23.45], \"item\": \"Cabinet\", \"price\": 199.99},\n",
        "        {\"vector\": [89.01, 34.56], \"item\": \"Bookshelf\", \"price\": 59.99},\n",
        "        {\"vector\": [90.12, 45.67], \"item\": \"Monitor\", \"price\": 129.99},\n",
        "        {\"vector\": [15.23, 35.67], \"item\": \"Keyboard\", \"price\": 39.99},\n",
        "        {\"vector\": [25.34, 45.78], \"item\": \"Mouse\", \"price\": 19.99},\n",
        "        {\"vector\": [35.45, 55.89], \"item\": \"Printer\", \"price\": 89.99},\n",
        "        {\"vector\": [45.56, 65.90], \"item\": \"Scanner\", \"price\": 59.99},\n",
        "        {\"vector\": [55.67, 75.01], \"item\": \"Router\", \"price\": 49.99},\n",
        "        {\"vector\": [65.78, 85.12], \"item\": \"Switch\", \"price\": 29.99},\n",
        "        {\"vector\": [75.89, 95.23], \"item\": \"Speaker\", \"price\": 24.99},\n",
        "        {\"vector\": [85.90, 12.34], \"item\": \"Headphones\", \"price\": 19.99},\n",
        "        {\"vector\": [95.01, 22.45], \"item\": \"Webcam\", \"price\": 34.99},\n",
        "        {\"vector\": [10.12, 32.56], \"item\": \"Microphone\", \"price\": 59.99},\n",
        "        {\"vector\": [20.23, 42.67], \"item\": \"Tablet\", \"price\": 199.99},\n",
        "        {\"vector\": [30.34, 52.78], \"item\": \"Smartphone\", \"price\": 699.99},\n",
        "        {\"vector\": [40.45, 62.89], \"item\": \"TV\", \"price\": 499.99},\n",
        "        {\"vector\": [50.56, 72.90], \"item\": \"Blender\", \"price\": 39.99},\n",
        "        {\"vector\": [60.67, 82.01], \"item\": \"Toaster\", \"price\": 19.99},\n",
        "        {\"vector\": [70.78, 92.12], \"item\": \"Mixer\", \"price\": 89.99},\n",
        "        {\"vector\": [80.89, 10.23], \"item\": \"Coffee Maker\", \"price\": 59.99},\n",
        "        {\"vector\": [90.90, 20.34], \"item\": \"Air Conditioner\", \"price\": 299.99},\n",
        "        {\"vector\": [11.01, 30.45], \"item\": \"Heater\", \"price\": 49.99},\n",
        "        {\"vector\": [21.12, 40.56], \"item\": \"Fan\", \"price\": 24.99},\n",
        "        {\"vector\": [31.23, 50.67], \"item\": \"Vacuum Cleaner\", \"price\": 149.99},\n",
        "        {\"vector\": [41.34, 60.78], \"item\": \"Washing Machine\", \"price\": 399.99},\n",
        "        {\"vector\": [51.45, 70.89], \"item\": \"Dryer\", \"price\": 349.99},\n",
        "        {\"vector\": [61.56, 80.90], \"item\": \"Refrigerator\", \"price\": 599.99},\n",
        "        {\"vector\": [71.67, 90.01], \"item\": \"Oven\", \"price\": 299.99},\n",
        "        {\"vector\": [81.78, 10.12], \"item\": \"Dishwasher\", \"price\": 249.99},\n",
        "        {\"vector\": [91.89, 20.23], \"item\": \"Microwave\", \"price\": 99.99},\n",
        "        {\"vector\": [13.14, 30.34], \"item\": \"Electric Kettle\", \"price\": 29.99},\n",
        "        {\"vector\": [23.25, 40.45], \"item\": \"Rice Cooker\", \"price\": 39.99},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXFgxKmv77S6",
        "outputId": "bff6f340-f56a-4cec-c065-fc309728fc3e"
      },
      "outputs": [],
      "source": [
        "'''It is recommended to use iterators to add large datasets in batches.\n",
        "But for simplicity we used manually adding batches.'''\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "start_index = 0\n",
        "\n",
        "# Iterate over the DataFrame in chunks (batches)\n",
        "for i in tqdm(range(start_index, len(df), batch_size)):\n",
        "    # Slice the DataFrame for the current batch\n",
        "    batch_df = df.iloc[i : i + batch_size]\n",
        "\n",
        "    # Prepare a list to store the data in LanceDB-friendly format\n",
        "    batch_data = []\n",
        "    for _, row in batch_df.iterrows():\n",
        "        data_dict = {\n",
        "            \"vector\": row[\"vector\"],\n",
        "            \"item\": row[\"item\"],\n",
        "            \"price\": row[\"price\"]\n",
        "        }\n",
        "        batch_data.append(data_dict)\n",
        "\n",
        "    # Add the batch to your LanceDB table\n",
        "    tbl.add(batch_data)\n",
        "\n",
        "print(\"Data has been added to the table in batches.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcE6ErUC_-BB"
      },
      "source": [
        "##### Using Iterators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MTo6eNdq_sf_"
      },
      "outputs": [],
      "source": [
        "def df_to_dict_batches(df: pd.DataFrame, batch_size: int = 128):\n",
        "    \"\"\"\n",
        "    Yields data from a DataFrame in batches of dictionaries.\n",
        "    Each batch is a list of dict, suitable for LanceDB ingestion.\n",
        "    \"\"\"\n",
        "    for start_idx in range(0, len(df), batch_size):\n",
        "        end_idx = start_idx + batch_size\n",
        "        # Convert the batch of rows to a list of dict\n",
        "        batch_dicts = df.iloc[start_idx:end_idx].to_dict(orient=\"records\")\n",
        "        yield batch_dicts\n",
        "\n",
        "tbl = db.create_table(\n",
        "    \"batch_iterator_table\",\n",
        "    data=df_to_dict_batches(df, batch_size=10),  # <-- the iterator\n",
        "    schema=DataSchema\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CD4WDTfwAD59",
        "outputId": "5212ef09-5217-4976-cebc-dd9f644ae3f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vector</th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[12.34, 56.78]</td>\n",
              "      <td>Chair</td>\n",
              "      <td>49.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[23.45, 67.89]</td>\n",
              "      <td>Table</td>\n",
              "      <td>89.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[34.56, 78.9]</td>\n",
              "      <td>Lamp</td>\n",
              "      <td>29.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[45.67, 89.01]</td>\n",
              "      <td>Sofa</td>\n",
              "      <td>299.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[56.78, 90.12]</td>\n",
              "      <td>Desk</td>\n",
              "      <td>149.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[67.89, 12.34]</td>\n",
              "      <td>Bed</td>\n",
              "      <td>399.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[78.9, 23.45]</td>\n",
              "      <td>Cabinet</td>\n",
              "      <td>199.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[89.01, 34.56]</td>\n",
              "      <td>Bookshelf</td>\n",
              "      <td>59.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[90.12, 45.67]</td>\n",
              "      <td>Monitor</td>\n",
              "      <td>129.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[15.23, 35.67]</td>\n",
              "      <td>Keyboard</td>\n",
              "      <td>39.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[25.34, 45.78]</td>\n",
              "      <td>Mouse</td>\n",
              "      <td>19.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[35.45, 55.89]</td>\n",
              "      <td>Printer</td>\n",
              "      <td>89.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[45.56, 65.9]</td>\n",
              "      <td>Scanner</td>\n",
              "      <td>59.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[55.67, 75.01]</td>\n",
              "      <td>Router</td>\n",
              "      <td>49.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[65.78, 85.12]</td>\n",
              "      <td>Switch</td>\n",
              "      <td>29.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[75.89, 95.23]</td>\n",
              "      <td>Speaker</td>\n",
              "      <td>24.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[85.9, 12.34]</td>\n",
              "      <td>Headphones</td>\n",
              "      <td>19.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[95.01, 22.45]</td>\n",
              "      <td>Webcam</td>\n",
              "      <td>34.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[10.12, 32.56]</td>\n",
              "      <td>Microphone</td>\n",
              "      <td>59.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[20.23, 42.67]</td>\n",
              "      <td>Tablet</td>\n",
              "      <td>199.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[30.34, 52.78]</td>\n",
              "      <td>Smartphone</td>\n",
              "      <td>699.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[40.45, 62.89]</td>\n",
              "      <td>TV</td>\n",
              "      <td>499.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[50.56, 72.9]</td>\n",
              "      <td>Blender</td>\n",
              "      <td>39.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[60.67, 82.01]</td>\n",
              "      <td>Toaster</td>\n",
              "      <td>19.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[70.78, 92.12]</td>\n",
              "      <td>Mixer</td>\n",
              "      <td>89.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[80.89, 10.23]</td>\n",
              "      <td>Coffee Maker</td>\n",
              "      <td>59.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[90.9, 20.34]</td>\n",
              "      <td>Air Conditioner</td>\n",
              "      <td>299.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[11.01, 30.45]</td>\n",
              "      <td>Heater</td>\n",
              "      <td>49.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[21.12, 40.56]</td>\n",
              "      <td>Fan</td>\n",
              "      <td>24.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[31.23, 50.67]</td>\n",
              "      <td>Vacuum Cleaner</td>\n",
              "      <td>149.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[41.34, 60.78]</td>\n",
              "      <td>Washing Machine</td>\n",
              "      <td>399.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[51.45, 70.89]</td>\n",
              "      <td>Dryer</td>\n",
              "      <td>349.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[61.56, 80.9]</td>\n",
              "      <td>Refrigerator</td>\n",
              "      <td>599.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[71.67, 90.01]</td>\n",
              "      <td>Oven</td>\n",
              "      <td>299.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[81.78, 10.12]</td>\n",
              "      <td>Dishwasher</td>\n",
              "      <td>249.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[91.89, 20.23]</td>\n",
              "      <td>Microwave</td>\n",
              "      <td>99.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[13.14, 30.34]</td>\n",
              "      <td>Electric Kettle</td>\n",
              "      <td>29.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[23.25, 40.45]</td>\n",
              "      <td>Rice Cooker</td>\n",
              "      <td>39.99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            vector             item   price\n",
              "0   [12.34, 56.78]            Chair   49.99\n",
              "1   [23.45, 67.89]            Table   89.99\n",
              "2    [34.56, 78.9]             Lamp   29.99\n",
              "3   [45.67, 89.01]             Sofa  299.99\n",
              "4   [56.78, 90.12]             Desk  149.99\n",
              "5   [67.89, 12.34]              Bed  399.99\n",
              "6    [78.9, 23.45]          Cabinet  199.99\n",
              "7   [89.01, 34.56]        Bookshelf   59.99\n",
              "8   [90.12, 45.67]          Monitor  129.99\n",
              "9   [15.23, 35.67]         Keyboard   39.99\n",
              "10  [25.34, 45.78]            Mouse   19.99\n",
              "11  [35.45, 55.89]          Printer   89.99\n",
              "12   [45.56, 65.9]          Scanner   59.99\n",
              "13  [55.67, 75.01]           Router   49.99\n",
              "14  [65.78, 85.12]           Switch   29.99\n",
              "15  [75.89, 95.23]          Speaker   24.99\n",
              "16   [85.9, 12.34]       Headphones   19.99\n",
              "17  [95.01, 22.45]           Webcam   34.99\n",
              "18  [10.12, 32.56]       Microphone   59.99\n",
              "19  [20.23, 42.67]           Tablet  199.99\n",
              "20  [30.34, 52.78]       Smartphone  699.99\n",
              "21  [40.45, 62.89]               TV  499.99\n",
              "22   [50.56, 72.9]          Blender   39.99\n",
              "23  [60.67, 82.01]          Toaster   19.99\n",
              "24  [70.78, 92.12]            Mixer   89.99\n",
              "25  [80.89, 10.23]     Coffee Maker   59.99\n",
              "26   [90.9, 20.34]  Air Conditioner  299.99\n",
              "27  [11.01, 30.45]           Heater   49.99\n",
              "28  [21.12, 40.56]              Fan   24.99\n",
              "29  [31.23, 50.67]   Vacuum Cleaner  149.99\n",
              "30  [41.34, 60.78]  Washing Machine  399.99\n",
              "31  [51.45, 70.89]            Dryer  349.99\n",
              "32   [61.56, 80.9]     Refrigerator  599.99\n",
              "33  [71.67, 90.01]             Oven  299.99\n",
              "34  [81.78, 10.12]       Dishwasher  249.99\n",
              "35  [91.89, 20.23]        Microwave   99.99\n",
              "36  [13.14, 30.34]  Electric Kettle   29.99\n",
              "37  [23.25, 40.45]      Rice Cooker   39.99"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrawYOTzysSy"
      },
      "source": [
        "### Open an existing table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFeqwxtjyu0x",
        "outputId": "f242ccd3-2d6e-43ff-8257-d8509910ad6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['batch_iterator_table', 'empty_table', 'my_table']\n"
          ]
        }
      ],
      "source": [
        "print(db.table_names())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SysAn2HVyx0M"
      },
      "outputs": [],
      "source": [
        "tbl = db.open_table(\"my_table\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaO5aEfXzAia"
      },
      "source": [
        "### Search for nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3BBfsp7zCdh",
        "outputId": "8ec07933-7b1e-4e30-8092-bbde8c049b52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'vector': [3.0999999046325684, 4.099999904632568],\n",
              "  'item': 'foo',\n",
              "  'price': 10.0,\n",
              "  '_distance': 0.07999993860721588}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.search([3.3, 3.9]).limit(1).to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmaOxQ75Af4P"
      },
      "source": [
        "#### Add metric for distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "NLYZVBDzzYKQ",
        "outputId": "28d4bebc-c776-42eb-ce58-7d57d4369633"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vector</th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "      <th>_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[5.9, 26.5]</td>\n",
              "      <td>bar</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.002131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[3.1, 4.1]</td>\n",
              "      <td>foo</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.119375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        vector item  price  _distance\n",
              "0  [5.9, 26.5]  bar   20.0   0.002131\n",
              "1   [3.1, 4.1]  foo   10.0   0.119375"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Metrics can be: default='l2', 'cosine', 'dot'\n",
        "tbl.search([3.1, 20]).metric(\"cosine\").limit(2).to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "SlEFQA1_-CXb",
        "outputId": "caed2b9f-c7a4-48ab-cfa3-5a856627fb24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vector</th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "      <th>_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[7.0, 7.0]</td>\n",
              "      <td>jar</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1.0, 1.0]</td>\n",
              "      <td>tar</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5812.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       vector item  price  _distance\n",
              "0  [7.0, 7.0]  jar  200.0     4900.0\n",
              "1  [1.0, 1.0]  tar  100.0     5812.0"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl2 = db.open_table(\"empty_table\")\n",
        "tbl2.search([77, 7]).limit(5).to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lczgni40B8E"
      },
      "source": [
        "### Delete and Drop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt1ND4-X0W1x"
      },
      "source": [
        "#### Delete a row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vector</th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[3.1, 4.1]</td>\n",
              "      <td>foo</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5.9, 26.5]</td>\n",
              "      <td>bar</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[10.0, 13.0]</td>\n",
              "      <td>fizz</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         vector  item  price\n",
              "0    [3.1, 4.1]   foo   10.0\n",
              "1   [5.9, 26.5]   bar   20.0\n",
              "2  [10.0, 13.0]  fizz    1.0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9DtdUXfY0ZhK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vector</th>\n",
              "      <th>item</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[3.1, 4.1]</td>\n",
              "      <td>foo</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[5.9, 26.5]</td>\n",
              "      <td>bar</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        vector item  price\n",
              "0   [3.1, 4.1]  foo   10.0\n",
              "1  [5.9, 26.5]  bar   20.0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.delete('item = \"fizz\"')\n",
        "tbl.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nquqtgD0dql"
      },
      "source": [
        "#### Drop a table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Zu_yZ_0W0f8g"
      },
      "outputs": [],
      "source": [
        "db.drop_table(\"my_table\")\n",
        "db.drop_table(\"empty_table\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeRZKs2qBZBb"
      },
      "source": [
        "## 2. Working with Text and Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG_HPn6gLNEg"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "30Khv6JyLP57",
        "outputId": "f48ef9b2-f3c2-481b-9649-e312bf81f736"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>difficulty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Introduction to Neural Networks</td>\n",
              "      <td>An overview of neural networks, their architec...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformers in NLP</td>\n",
              "      <td>Explores the transformer architecture, its rol...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Reinforcement Learning Basics</td>\n",
              "      <td>Covers the fundamental concepts of reinforceme...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Information Retrieval Systems</td>\n",
              "      <td>Discusses the principles behind information re...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Convolutional Neural Networks Explained</td>\n",
              "      <td>Delves into convolutional neural networks, the...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BERT for Language Understanding</td>\n",
              "      <td>An in-depth look at BERT (Bidirectional Encode...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Semantic Search Techniques</td>\n",
              "      <td>Explores advanced search techniques that under...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Support Vector Machines</td>\n",
              "      <td>Introduces Support Vector Machines, their math...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Generative Adversarial Networks</td>\n",
              "      <td>Covers the concept of GANs, their architecture...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Word Embeddings in NLP</td>\n",
              "      <td>Discusses word embeddings like Word2Vec and Gl...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Deep Reinforcement Learning</td>\n",
              "      <td>Combines deep learning with reinforcement lear...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Natural Language Generation</td>\n",
              "      <td>Explores techniques for generating human-like ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Attention Mechanisms in Deep Learning</td>\n",
              "      <td>Details how attention mechanisms enhance neura...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Clustering Algorithms Overview</td>\n",
              "      <td>Provides an overview of clustering algorithms ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sequence-to-Sequence Models</td>\n",
              "      <td>Examines seq2seq models used in tasks like mac...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Dimensionality Reduction Techniques</td>\n",
              "      <td>Covers techniques like PCA and t-SNE for reduc...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Ethics in Artificial Intelligence</td>\n",
              "      <td>Discusses the ethical considerations in AI dev...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Transfer Learning in Deep Learning</td>\n",
              "      <td>Explores how transfer learning leverages pre-t...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Time Series Forecasting with LSTMs</td>\n",
              "      <td>Details the use of Long Short-Term Memory netw...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Graph Neural Networks</td>\n",
              "      <td>Introduces graph neural networks and their app...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Hyperparameter Tuning Strategies</td>\n",
              "      <td>Covers methods for optimizing hyperparameters ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Ensemble Methods in Machine Learning</td>\n",
              "      <td>Explores ensemble techniques like Random Fores...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Autoencoders for Data Compression</td>\n",
              "      <td>Discusses autoencoders and their role in unsup...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Recurrent Neural Networks Fundamentals</td>\n",
              "      <td>Provides an introduction to RNNs, their struct...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Zero-Shot Learning Techniques</td>\n",
              "      <td>Examines methods that enable models to recogni...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Machine Translation with Transformers</td>\n",
              "      <td>Details how transformer models are applied to ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Adversarial Machine Learning</td>\n",
              "      <td>Explores how adversarial examples can deceive ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Natural Language Understanding</td>\n",
              "      <td>Covers the processes and techniques involved i...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Data Augmentation in Deep Learning</td>\n",
              "      <td>Discusses techniques for artificially increasi...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Explainable AI (XAI)</td>\n",
              "      <td>Delves into methods and tools that make AI mod...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Federated Learning Concepts</td>\n",
              "      <td>Introduces federated learning, where models ar...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Optimization Algorithms in Machine Learning</td>\n",
              "      <td>Explores various optimization algorithms like ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Multi-Modal Learning Approaches</td>\n",
              "      <td>Covers techniques that integrate and process m...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          title  \\\n",
              "0               Introduction to Neural Networks   \n",
              "1                           Transformers in NLP   \n",
              "2                 Reinforcement Learning Basics   \n",
              "3                 Information Retrieval Systems   \n",
              "4       Convolutional Neural Networks Explained   \n",
              "5               BERT for Language Understanding   \n",
              "6                    Semantic Search Techniques   \n",
              "7                       Support Vector Machines   \n",
              "8               Generative Adversarial Networks   \n",
              "9                        Word Embeddings in NLP   \n",
              "10                  Deep Reinforcement Learning   \n",
              "11                  Natural Language Generation   \n",
              "12        Attention Mechanisms in Deep Learning   \n",
              "13               Clustering Algorithms Overview   \n",
              "14                  Sequence-to-Sequence Models   \n",
              "15          Dimensionality Reduction Techniques   \n",
              "16            Ethics in Artificial Intelligence   \n",
              "17           Transfer Learning in Deep Learning   \n",
              "18           Time Series Forecasting with LSTMs   \n",
              "19                        Graph Neural Networks   \n",
              "20             Hyperparameter Tuning Strategies   \n",
              "21         Ensemble Methods in Machine Learning   \n",
              "22            Autoencoders for Data Compression   \n",
              "23       Recurrent Neural Networks Fundamentals   \n",
              "24                Zero-Shot Learning Techniques   \n",
              "25        Machine Translation with Transformers   \n",
              "26                 Adversarial Machine Learning   \n",
              "27               Natural Language Understanding   \n",
              "28           Data Augmentation in Deep Learning   \n",
              "29                         Explainable AI (XAI)   \n",
              "30                  Federated Learning Concepts   \n",
              "31  Optimization Algorithms in Machine Learning   \n",
              "32              Multi-Modal Learning Approaches   \n",
              "\n",
              "                                              summary  difficulty  \n",
              "0   An overview of neural networks, their architec...           2  \n",
              "1   Explores the transformer architecture, its rol...           4  \n",
              "2   Covers the fundamental concepts of reinforceme...           3  \n",
              "3   Discusses the principles behind information re...           3  \n",
              "4   Delves into convolutional neural networks, the...           3  \n",
              "5   An in-depth look at BERT (Bidirectional Encode...           4  \n",
              "6   Explores advanced search techniques that under...           4  \n",
              "7   Introduces Support Vector Machines, their math...           3  \n",
              "8   Covers the concept of GANs, their architecture...           5  \n",
              "9   Discusses word embeddings like Word2Vec and Gl...           3  \n",
              "10  Combines deep learning with reinforcement lear...           5  \n",
              "11  Explores techniques for generating human-like ...           4  \n",
              "12  Details how attention mechanisms enhance neura...           4  \n",
              "13  Provides an overview of clustering algorithms ...           2  \n",
              "14  Examines seq2seq models used in tasks like mac...           4  \n",
              "15  Covers techniques like PCA and t-SNE for reduc...           3  \n",
              "16  Discusses the ethical considerations in AI dev...           2  \n",
              "17  Explores how transfer learning leverages pre-t...           3  \n",
              "18  Details the use of Long Short-Term Memory netw...           4  \n",
              "19  Introduces graph neural networks and their app...           5  \n",
              "20  Covers methods for optimizing hyperparameters ...           3  \n",
              "21  Explores ensemble techniques like Random Fores...           3  \n",
              "22  Discusses autoencoders and their role in unsup...           4  \n",
              "23  Provides an introduction to RNNs, their struct...           3  \n",
              "24  Examines methods that enable models to recogni...           5  \n",
              "25  Details how transformer models are applied to ...           4  \n",
              "26  Explores how adversarial examples can deceive ...           5  \n",
              "27  Covers the processes and techniques involved i...           3  \n",
              "28  Discusses techniques for artificially increasi...           2  \n",
              "29  Delves into methods and tools that make AI mod...           4  \n",
              "30  Introduces federated learning, where models ar...           4  \n",
              "31  Explores various optimization algorithms like ...           3  \n",
              "32  Covers techniques that integrate and process m...           5  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    [\n",
        "        {\n",
        "            \"title\": \"Introduction to Neural Networks\",\n",
        "            \"summary\": \"An overview of neural networks, their architecture, and basic functioning, including neurons, layers, and activation functions.\",\n",
        "            \"difficulty\": 2\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Transformers in NLP\",\n",
        "            \"summary\": \"Explores the transformer architecture, its role in natural language processing tasks, and how it has revolutionized language models.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Reinforcement Learning Basics\",\n",
        "            \"summary\": \"Covers the fundamental concepts of reinforcement learning, including agents, environments, rewards, and policy optimization.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Information Retrieval Systems\",\n",
        "            \"summary\": \"Discusses the principles behind information retrieval systems, indexing, ranking algorithms, and evaluation metrics like precision and recall.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Convolutional Neural Networks Explained\",\n",
        "            \"summary\": \"Delves into convolutional neural networks, their layers, convolution operations, pooling, and applications in image recognition.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"BERT for Language Understanding\",\n",
        "            \"summary\": \"An in-depth look at BERT (Bidirectional Encoder Representations from Transformers) and its applications in understanding context in language processing.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Semantic Search Techniques\",\n",
        "            \"summary\": \"Explores advanced search techniques that understand the intent and contextual meaning of search queries to deliver more relevant results.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Support Vector Machines\",\n",
        "            \"summary\": \"Introduces Support Vector Machines, their mathematical foundation, and applications in classification and regression tasks.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Generative Adversarial Networks\",\n",
        "            \"summary\": \"Covers the concept of GANs, their architecture involving generators and discriminators, and their use in generating realistic data.\",\n",
        "            \"difficulty\": 5\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Word Embeddings in NLP\",\n",
        "            \"summary\": \"Discusses word embeddings like Word2Vec and GloVe, their importance in capturing semantic relationships between words, and their applications.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Deep Reinforcement Learning\",\n",
        "            \"summary\": \"Combines deep learning with reinforcement learning to solve complex tasks, highlighting algorithms like DQN and policy gradients.\",\n",
        "            \"difficulty\": 5\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Natural Language Generation\",\n",
        "            \"summary\": \"Explores techniques for generating human-like text, including rule-based methods and modern neural approaches like GPT.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Attention Mechanisms in Deep Learning\",\n",
        "            \"summary\": \"Details how attention mechanisms enhance neural network performance by allowing models to focus on relevant parts of the input.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Clustering Algorithms Overview\",\n",
        "            \"summary\": \"Provides an overview of clustering algorithms such as K-Means, Hierarchical Clustering, and DBSCAN, and their use cases.\",\n",
        "            \"difficulty\": 2\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Sequence-to-Sequence Models\",\n",
        "            \"summary\": \"Examines seq2seq models used in tasks like machine translation, including encoder-decoder architectures and attention.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Dimensionality Reduction Techniques\",\n",
        "            \"summary\": \"Covers techniques like PCA and t-SNE for reducing the dimensionality of data while preserving essential structures.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Ethics in Artificial Intelligence\",\n",
        "            \"summary\": \"Discusses the ethical considerations in AI development, including bias, fairness, transparency, and accountability.\",\n",
        "            \"difficulty\": 2\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Transfer Learning in Deep Learning\",\n",
        "            \"summary\": \"Explores how transfer learning leverages pre-trained models to improve performance on related tasks with limited data.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Time Series Forecasting with LSTMs\",\n",
        "            \"summary\": \"Details the use of Long Short-Term Memory networks for modeling and forecasting time-dependent data.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Graph Neural Networks\",\n",
        "            \"summary\": \"Introduces graph neural networks and their applications in processing graph-structured data for tasks like node classification.\",\n",
        "            \"difficulty\": 5\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Hyperparameter Tuning Strategies\",\n",
        "            \"summary\": \"Covers methods for optimizing hyperparameters in machine learning models, including grid search and Bayesian optimization.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Ensemble Methods in Machine Learning\",\n",
        "            \"summary\": \"Explores ensemble techniques like Random Forests and Gradient Boosting that combine multiple models to improve accuracy.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Autoencoders for Data Compression\",\n",
        "            \"summary\": \"Discusses autoencoders and their role in unsupervised learning for compressing and reconstructing data efficiently.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Recurrent Neural Networks Fundamentals\",\n",
        "            \"summary\": \"Provides an introduction to RNNs, their structure, and how they handle sequential data with feedback connections.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Zero-Shot Learning Techniques\",\n",
        "            \"summary\": \"Examines methods that enable models to recognize objects without having seen any training examples, using semantic information.\",\n",
        "            \"difficulty\": 5\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Machine Translation with Transformers\",\n",
        "            \"summary\": \"Details how transformer models are applied to machine translation tasks, outperforming traditional RNN-based approaches.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Adversarial Machine Learning\",\n",
        "            \"summary\": \"Explores how adversarial examples can deceive machine learning models and strategies to make models more robust.\",\n",
        "            \"difficulty\": 5\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Natural Language Understanding\",\n",
        "            \"summary\": \"Covers the processes and techniques involved in enabling machines to comprehend and interpret human language.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Data Augmentation in Deep Learning\",\n",
        "            \"summary\": \"Discusses techniques for artificially increasing the size of training datasets to improve model generalization.\",\n",
        "            \"difficulty\": 2\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Explainable AI (XAI)\",\n",
        "            \"summary\": \"Delves into methods and tools that make AI models' decisions transparent and understandable to humans.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Federated Learning Concepts\",\n",
        "            \"summary\": \"Introduces federated learning, where models are trained across multiple decentralized devices while keeping data localized.\",\n",
        "            \"difficulty\": 4\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Optimization Algorithms in Machine Learning\",\n",
        "            \"summary\": \"Explores various optimization algorithms like SGD, Adam, and RMSprop used to train machine learning models effectively.\",\n",
        "            \"difficulty\": 3\n",
        "        },\n",
        "        {\n",
        "            \"title\": \"Multi-Modal Learning Approaches\",\n",
        "            \"summary\": \"Covers techniques that integrate and process multiple types of data, such as text, images, and audio, within a single model.\",\n",
        "            \"difficulty\": 5\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYbxb1J1Sqgp"
      },
      "source": [
        "### Connect to DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LdU1HPB_SuH2"
      },
      "outputs": [],
      "source": [
        "import lancedb\n",
        "db = lancedb.connect(\".lancedb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwPx_O4-J5sT"
      },
      "source": [
        "### Define the embedding function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZTx_FpG7Jn3D"
      },
      "outputs": [],
      "source": [
        "from lancedb.embeddings import get_registry\n",
        "embedding_model = get_registry().get(\"sentence-transformers\").create(name=\"BAAI/bge-small-en-v1.5\", device=\"mps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_pz1tpWKB_y"
      },
      "source": [
        "### Define the data model or schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n9xJ4-twKFoI"
      },
      "outputs": [],
      "source": [
        "#You should put HF_TOKEN in the Notebook enviroment variables\n",
        "\n",
        "from lancedb.pydantic import LanceModel, Vector\n",
        "\n",
        "class StudyNotes(LanceModel):\n",
        "    title: str\n",
        "    summary: str = embedding_model.SourceField()\n",
        "    difficulty: int\n",
        "    vector: Vector(embedding_model.ndims()) = embedding_model.VectorField()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pv8QJi4KGM8"
      },
      "source": [
        "### Create table and add data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FfbaXjacKJDu"
      },
      "outputs": [],
      "source": [
        "def df_to_dict_batches(df: pd.DataFrame, batch_size: int = 128):\n",
        "    \"\"\"\n",
        "    Yields data from a DataFrame in batches of dictionaries.\n",
        "    Each batch is a list of dict, suitable for LanceDB ingestion.\n",
        "    \"\"\"\n",
        "    for start_idx in range(0, len(df), batch_size):\n",
        "        end_idx = start_idx + batch_size\n",
        "        # Convert the batch of rows to a list of dict\n",
        "        batch_dicts = df.iloc[start_idx:end_idx].to_dict(orient=\"records\")\n",
        "        yield batch_dicts\n",
        "\n",
        "tbl = db.create_table(\n",
        "    \"cs_notes_table\",\n",
        "    data=df_to_dict_batches(df, batch_size=10),\n",
        "    schema=StudyNotes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Introduction to Neural Networks</td>\n",
              "      <td>An overview of neural networks, their architec...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.019131705, -0.012864992, 0.02538711, -0.04...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Transformers in NLP</td>\n",
              "      <td>Explores the transformer architecture, its rol...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.03335983, 0.01862303, -0.00015819393, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Reinforcement Learning Basics</td>\n",
              "      <td>Covers the fundamental concepts of reinforceme...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.035786655, 0.04050146, 0.040627778, -0.021...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Information Retrieval Systems</td>\n",
              "      <td>Discusses the principles behind information re...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.034227632, 0.03347169, 0.0036248541, -0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Convolutional Neural Networks Explained</td>\n",
              "      <td>Delves into convolutional neural networks, the...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.025591748, -0.044624545, -0.0327766, -0.035...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BERT for Language Understanding</td>\n",
              "      <td>An in-depth look at BERT (Bidirectional Encode...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.048091616, -0.0010293722, -0.04051036, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Semantic Search Techniques</td>\n",
              "      <td>Explores advanced search techniques that under...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.05066493, 0.056105837, 0.013681952, -0.000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Support Vector Machines</td>\n",
              "      <td>Introduces Support Vector Machines, their math...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.002767832, -0.029321738, -0.011279432, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Generative Adversarial Networks</td>\n",
              "      <td>Covers the concept of GANs, their architecture...</td>\n",
              "      <td>5</td>\n",
              "      <td>[-0.01153428, 0.01732661, -0.0022153237, -0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Word Embeddings in NLP</td>\n",
              "      <td>Discusses word embeddings like Word2Vec and Gl...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.014825601, -0.0048156823, 0.0042675766, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Deep Reinforcement Learning</td>\n",
              "      <td>Combines deep learning with reinforcement lear...</td>\n",
              "      <td>5</td>\n",
              "      <td>[-0.083774425, 0.0031652367, 0.015555484, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Natural Language Generation</td>\n",
              "      <td>Explores techniques for generating human-like ...</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.011620809, 0.0832316, 0.0023099964, -0.0055...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Attention Mechanisms in Deep Learning</td>\n",
              "      <td>Details how attention mechanisms enhance neura...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.01007543, 0.01607964, 0.061395038, -0.0054...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Clustering Algorithms Overview</td>\n",
              "      <td>Provides an overview of clustering algorithms ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.041777343, -0.057141736, 0.009991821, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Sequence-to-Sequence Models</td>\n",
              "      <td>Examines seq2seq models used in tasks like mac...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.09775872, 0.016934851, -0.013716604, -0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Dimensionality Reduction Techniques</td>\n",
              "      <td>Covers techniques like PCA and t-SNE for reduc...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.0033684853, 0.046761263, 0.017188264, -0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Ethics in Artificial Intelligence</td>\n",
              "      <td>Discusses the ethical considerations in AI dev...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.007800452, -0.022573795, -0.0047734543, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Transfer Learning in Deep Learning</td>\n",
              "      <td>Explores how transfer learning leverages pre-t...</td>\n",
              "      <td>3</td>\n",
              "      <td>[0.010036865, 0.0027507993, 0.05202427, -0.013...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Time Series Forecasting with LSTMs</td>\n",
              "      <td>Details the use of Long Short-Term Memory netw...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.033762142, 0.05894408, 0.013803649, -0.019...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Graph Neural Networks</td>\n",
              "      <td>Introduces graph neural networks and their app...</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.008435795, -0.04032695, -0.018578824, -0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Hyperparameter Tuning Strategies</td>\n",
              "      <td>Covers methods for optimizing hyperparameters ...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.061589535, 0.040908407, 0.0038018697, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Ensemble Methods in Machine Learning</td>\n",
              "      <td>Explores ensemble techniques like Random Fores...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.053640816, 0.029869916, 0.023286609, 0.006...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Autoencoders for Data Compression</td>\n",
              "      <td>Discusses autoencoders and their role in unsup...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.0008582097, 0.0154731665, -0.019677423, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Recurrent Neural Networks Fundamentals</td>\n",
              "      <td>Provides an introduction to RNNs, their struct...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.06397145, -0.014723847, 0.029859072, -0.05...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Zero-Shot Learning Techniques</td>\n",
              "      <td>Examines methods that enable models to recogni...</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.01061004, 0.04981825, -0.022400582, -0.0186...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Machine Translation with Transformers</td>\n",
              "      <td>Details how transformer models are applied to ...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.048571706, 0.016223863, 0.012704103, -0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Adversarial Machine Learning</td>\n",
              "      <td>Explores how adversarial examples can deceive ...</td>\n",
              "      <td>5</td>\n",
              "      <td>[-0.03267083, -0.021881485, -0.016787335, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Natural Language Understanding</td>\n",
              "      <td>Covers the processes and techniques involved i...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.008330684, 0.025997736, 0.036576882, -0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Data Augmentation in Deep Learning</td>\n",
              "      <td>Discusses techniques for artificially increasi...</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.00042642147, 0.03388558, 0.06320969, -0.047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Explainable AI (XAI)</td>\n",
              "      <td>Delves into methods and tools that make AI mod...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.010751237, 0.025575902, 0.04404144, -0.008...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Federated Learning Concepts</td>\n",
              "      <td>Introduces federated learning, where models ar...</td>\n",
              "      <td>4</td>\n",
              "      <td>[0.031146023, -0.06630368, -0.00069586106, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Optimization Algorithms in Machine Learning</td>\n",
              "      <td>Explores various optimization algorithms like ...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.04154815, 0.0023184884, 0.026838638, -0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Multi-Modal Learning Approaches</td>\n",
              "      <td>Covers techniques that integrate and process m...</td>\n",
              "      <td>5</td>\n",
              "      <td>[0.019347835, 0.03163664, 0.040617593, -0.0530...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          title  \\\n",
              "0               Introduction to Neural Networks   \n",
              "1                           Transformers in NLP   \n",
              "2                 Reinforcement Learning Basics   \n",
              "3                 Information Retrieval Systems   \n",
              "4       Convolutional Neural Networks Explained   \n",
              "5               BERT for Language Understanding   \n",
              "6                    Semantic Search Techniques   \n",
              "7                       Support Vector Machines   \n",
              "8               Generative Adversarial Networks   \n",
              "9                        Word Embeddings in NLP   \n",
              "10                  Deep Reinforcement Learning   \n",
              "11                  Natural Language Generation   \n",
              "12        Attention Mechanisms in Deep Learning   \n",
              "13               Clustering Algorithms Overview   \n",
              "14                  Sequence-to-Sequence Models   \n",
              "15          Dimensionality Reduction Techniques   \n",
              "16            Ethics in Artificial Intelligence   \n",
              "17           Transfer Learning in Deep Learning   \n",
              "18           Time Series Forecasting with LSTMs   \n",
              "19                        Graph Neural Networks   \n",
              "20             Hyperparameter Tuning Strategies   \n",
              "21         Ensemble Methods in Machine Learning   \n",
              "22            Autoencoders for Data Compression   \n",
              "23       Recurrent Neural Networks Fundamentals   \n",
              "24                Zero-Shot Learning Techniques   \n",
              "25        Machine Translation with Transformers   \n",
              "26                 Adversarial Machine Learning   \n",
              "27               Natural Language Understanding   \n",
              "28           Data Augmentation in Deep Learning   \n",
              "29                         Explainable AI (XAI)   \n",
              "30                  Federated Learning Concepts   \n",
              "31  Optimization Algorithms in Machine Learning   \n",
              "32              Multi-Modal Learning Approaches   \n",
              "\n",
              "                                              summary  difficulty  \\\n",
              "0   An overview of neural networks, their architec...           2   \n",
              "1   Explores the transformer architecture, its rol...           4   \n",
              "2   Covers the fundamental concepts of reinforceme...           3   \n",
              "3   Discusses the principles behind information re...           3   \n",
              "4   Delves into convolutional neural networks, the...           3   \n",
              "5   An in-depth look at BERT (Bidirectional Encode...           4   \n",
              "6   Explores advanced search techniques that under...           4   \n",
              "7   Introduces Support Vector Machines, their math...           3   \n",
              "8   Covers the concept of GANs, their architecture...           5   \n",
              "9   Discusses word embeddings like Word2Vec and Gl...           3   \n",
              "10  Combines deep learning with reinforcement lear...           5   \n",
              "11  Explores techniques for generating human-like ...           4   \n",
              "12  Details how attention mechanisms enhance neura...           4   \n",
              "13  Provides an overview of clustering algorithms ...           2   \n",
              "14  Examines seq2seq models used in tasks like mac...           4   \n",
              "15  Covers techniques like PCA and t-SNE for reduc...           3   \n",
              "16  Discusses the ethical considerations in AI dev...           2   \n",
              "17  Explores how transfer learning leverages pre-t...           3   \n",
              "18  Details the use of Long Short-Term Memory netw...           4   \n",
              "19  Introduces graph neural networks and their app...           5   \n",
              "20  Covers methods for optimizing hyperparameters ...           3   \n",
              "21  Explores ensemble techniques like Random Fores...           3   \n",
              "22  Discusses autoencoders and their role in unsup...           4   \n",
              "23  Provides an introduction to RNNs, their struct...           3   \n",
              "24  Examines methods that enable models to recogni...           5   \n",
              "25  Details how transformer models are applied to ...           4   \n",
              "26  Explores how adversarial examples can deceive ...           5   \n",
              "27  Covers the processes and techniques involved i...           3   \n",
              "28  Discusses techniques for artificially increasi...           2   \n",
              "29  Delves into methods and tools that make AI mod...           4   \n",
              "30  Introduces federated learning, where models ar...           4   \n",
              "31  Explores various optimization algorithms like ...           3   \n",
              "32  Covers techniques that integrate and process m...           5   \n",
              "\n",
              "                                               vector  \n",
              "0   [-0.019131705, -0.012864992, 0.02538711, -0.04...  \n",
              "1   [-0.03335983, 0.01862303, -0.00015819393, -0.0...  \n",
              "2   [-0.035786655, 0.04050146, 0.040627778, -0.021...  \n",
              "3   [-0.034227632, 0.03347169, 0.0036248541, -0.00...  \n",
              "4   [0.025591748, -0.044624545, -0.0327766, -0.035...  \n",
              "5   [-0.048091616, -0.0010293722, -0.04051036, -0....  \n",
              "6   [-0.05066493, 0.056105837, 0.013681952, -0.000...  \n",
              "7   [-0.002767832, -0.029321738, -0.011279432, -0....  \n",
              "8   [-0.01153428, 0.01732661, -0.0022153237, -0.00...  \n",
              "9   [-0.014825601, -0.0048156823, 0.0042675766, -0...  \n",
              "10  [-0.083774425, 0.0031652367, 0.015555484, 0.00...  \n",
              "11  [0.011620809, 0.0832316, 0.0023099964, -0.0055...  \n",
              "12  [-0.01007543, 0.01607964, 0.061395038, -0.0054...  \n",
              "13  [-0.041777343, -0.057141736, 0.009991821, -0.0...  \n",
              "14  [-0.09775872, 0.016934851, -0.013716604, -0.01...  \n",
              "15  [0.0033684853, 0.046761263, 0.017188264, -0.01...  \n",
              "16  [-0.007800452, -0.022573795, -0.0047734543, -0...  \n",
              "17  [0.010036865, 0.0027507993, 0.05202427, -0.013...  \n",
              "18  [-0.033762142, 0.05894408, 0.013803649, -0.019...  \n",
              "19  [0.008435795, -0.04032695, -0.018578824, -0.03...  \n",
              "20  [-0.061589535, 0.040908407, 0.0038018697, 0.03...  \n",
              "21  [-0.053640816, 0.029869916, 0.023286609, 0.006...  \n",
              "22  [-0.0008582097, 0.0154731665, -0.019677423, -0...  \n",
              "23  [-0.06397145, -0.014723847, 0.029859072, -0.05...  \n",
              "24  [0.01061004, 0.04981825, -0.022400582, -0.0186...  \n",
              "25  [-0.048571706, 0.016223863, 0.012704103, -0.01...  \n",
              "26  [-0.03267083, -0.021881485, -0.016787335, 0.00...  \n",
              "27  [-0.008330684, 0.025997736, 0.036576882, -0.01...  \n",
              "28  [0.00042642147, 0.03388558, 0.06320969, -0.047...  \n",
              "29  [-0.010751237, 0.025575902, 0.04404144, -0.008...  \n",
              "30  [0.031146023, -0.06630368, -0.00069586106, -0....  \n",
              "31  [-0.04154815, 0.0023184884, 0.026838638, -0.01...  \n",
              "32  [0.019347835, 0.03163664, 0.040617593, -0.0530...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk8woZQrKLqi"
      },
      "source": [
        "### Querying your table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "PXZRyyR-KNyi",
        "outputId": "d7257a59-3659-4f00-cd14-8511f7e2fb72"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>vector</th>\n",
              "      <th>_distance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Transformers in NLP</td>\n",
              "      <td>Explores the transformer architecture, its rol...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.03335983, 0.01862303, -0.00015819393, -0.0...</td>\n",
              "      <td>0.809757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BERT for Language Understanding</td>\n",
              "      <td>An in-depth look at BERT (Bidirectional Encode...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.048091616, -0.0010293722, -0.04051036, -0....</td>\n",
              "      <td>0.830706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Natural Language Understanding</td>\n",
              "      <td>Covers the processes and techniques involved i...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.008330684, 0.025997736, 0.036576882, -0.01...</td>\n",
              "      <td>0.852595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Machine Translation with Transformers</td>\n",
              "      <td>Details how transformer models are applied to ...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.048571706, 0.016223863, 0.012704103, -0.01...</td>\n",
              "      <td>0.889645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Word Embeddings in NLP</td>\n",
              "      <td>Discusses word embeddings like Word2Vec and Gl...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.014825601, -0.0048156823, 0.0042675766, -0...</td>\n",
              "      <td>0.890143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   title  \\\n",
              "0                    Transformers in NLP   \n",
              "1        BERT for Language Understanding   \n",
              "2         Natural Language Understanding   \n",
              "3  Machine Translation with Transformers   \n",
              "4                 Word Embeddings in NLP   \n",
              "\n",
              "                                             summary  difficulty  \\\n",
              "0  Explores the transformer architecture, its rol...           4   \n",
              "1  An in-depth look at BERT (Bidirectional Encode...           4   \n",
              "2  Covers the processes and techniques involved i...           3   \n",
              "3  Details how transformer models are applied to ...           4   \n",
              "4  Discusses word embeddings like Word2Vec and Gl...           3   \n",
              "\n",
              "                                              vector  _distance  \n",
              "0  [-0.03335983, 0.01862303, -0.00015819393, -0.0...   0.809757  \n",
              "1  [-0.048091616, -0.0010293722, -0.04051036, -0....   0.830706  \n",
              "2  [-0.008330684, 0.025997736, 0.036576882, -0.01...   0.852595  \n",
              "3  [-0.048571706, 0.016223863, 0.012704103, -0.01...   0.889645  \n",
              "4  [-0.014825601, -0.0048156823, 0.0042675766, -0...   0.890143  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What does NLP stands for?\"\n",
        "#actual = table.search(query).limit(5).to_pydantic(Words)[0]\n",
        "tbl.search(query).limit(5).to_pandas()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDRIxjdZLbOA"
      },
      "source": [
        "#### Hybrid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "nH7zFNt7LeOC",
        "outputId": "7265c594-087a-438c-9c9b-1daa0e0c17f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>summary</th>\n",
              "      <th>difficulty</th>\n",
              "      <th>vector</th>\n",
              "      <th>_relevance_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Transformers in NLP</td>\n",
              "      <td>Explores the transformer architecture, its rol...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.03335983, 0.01862303, -0.00015819393, -0.0...</td>\n",
              "      <td>0.016393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Augmentation in Deep Learning</td>\n",
              "      <td>Discusses techniques for artificially increasi...</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.00042642147, 0.03388558, 0.06320969, -0.047...</td>\n",
              "      <td>0.016393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BERT for Language Understanding</td>\n",
              "      <td>An in-depth look at BERT (Bidirectional Encode...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.048091616, -0.0010293722, -0.04051036, -0....</td>\n",
              "      <td>0.016129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Autoencoders for Data Compression</td>\n",
              "      <td>Discusses autoencoders and their role in unsup...</td>\n",
              "      <td>4</td>\n",
              "      <td>[-0.0008582097, 0.0154731665, -0.019677423, -0...</td>\n",
              "      <td>0.016129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Natural Language Understanding</td>\n",
              "      <td>Covers the processes and techniques involved i...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.008330684, 0.025997736, 0.036576882, -0.01...</td>\n",
              "      <td>0.015873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                title  \\\n",
              "0                 Transformers in NLP   \n",
              "1  Data Augmentation in Deep Learning   \n",
              "2     BERT for Language Understanding   \n",
              "3   Autoencoders for Data Compression   \n",
              "4      Natural Language Understanding   \n",
              "\n",
              "                                             summary  difficulty  \\\n",
              "0  Explores the transformer architecture, its rol...           4   \n",
              "1  Discusses techniques for artificially increasi...           2   \n",
              "2  An in-depth look at BERT (Bidirectional Encode...           4   \n",
              "3  Discusses autoencoders and their role in unsup...           4   \n",
              "4  Covers the processes and techniques involved i...           3   \n",
              "\n",
              "                                              vector  _relevance_score  \n",
              "0  [-0.03335983, 0.01862303, -0.00015819393, -0.0...          0.016393  \n",
              "1  [0.00042642147, 0.03388558, 0.06320969, -0.047...          0.016393  \n",
              "2  [-0.048091616, -0.0010293722, -0.04051036, -0....          0.016129  \n",
              "3  [-0.0008582097, 0.0154731665, -0.019677423, -0...          0.016129  \n",
              "4  [-0.008330684, 0.025997736, 0.036576882, -0.01...          0.015873  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tbl.create_fts_index('summary', use_tantivy=False)\n",
        "tbl.search(query, query_type=\"hybrid\").limit(5).to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcSUHD7TLaY7"
      },
      "source": [
        "# Working with LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNyRIWn0Le5v"
      },
      "source": [
        "## LLMs API providers Clients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvS2Lbl1Piks"
      },
      "source": [
        "### Install OpenAI client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbbFd7x5L2lc",
        "outputId": "9983ca8b-d9e5-4c0f-e422-8609d98d3157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.58.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.7.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.10.4)\n",
            "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./.venv/lib/python3.11/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ25LTh2Poh_"
      },
      "source": [
        "### Make a client object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JRbJoC_9LdyL"
      },
      "outputs": [],
      "source": [
        "GROK_BASE_URL = \"https://api.x.ai/v1\"\n",
        "\n",
        "#If you are using Google Colab save in your Keys and then\n",
        "'''from google.colab import userdata\n",
        "GROK_API_KEY = userdata.get('GROK_API_KEY')'''\n",
        "\n",
        "#If running locally save in your environment variables (based on OS)\n",
        "import os\n",
        "GROK_API_KEY = os.getenv(\"GROK_API_KEY\")\n",
        "GROK_MODEL_NAME = \"grok-2-1212\"\n",
        "\n",
        "from openai import OpenAI\n",
        "grok_client = OpenAI(api_key=GROK_API_KEY, base_url=GROK_BASE_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTt-4OrSQTj5"
      },
      "source": [
        "### Hello World"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEsm33wZQWoS",
        "outputId": "02daa9b0-fa14-401d-d6c2-b4c330a5cf75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "response = grok_client.chat.completions.create(\n",
        "  model=GROK_MODEL_NAME,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello World!\"},\n",
        "  ],\n",
        "  temperature = 0.3\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq8tLka_RSn6",
        "outputId": "b3c87c8e-90df-4a3a-e9eb-b6c66afec6c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='62b58c8d-d83d-4ae7-b179-6a71b50cde07', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1735479157, model='grok-2-1212', object='chat.completion', service_tier=None, system_fingerprint='fp_149a247ffa', usage=CompletionUsage(completion_tokens=10, prompt_tokens=19, total_tokens=29, completion_tokens_details=None, prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0, text_tokens=19, image_tokens=0)))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gERyuvnNRjTA"
      },
      "source": [
        "### Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL59Bi2KRmQx",
        "outputId": "1b399831-201b-404e-b480-a10895034aa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To solve the expression \\(6 + 4 \\times 5 - 1\\) step by step, we need to follow the order of operations, often remembered by the acronym PEMDAS (Parentheses, Exponents, Multiplication and Division (from left to right), Addition and Subtraction (from left to right)).\n",
            "\n",
            "Let's break it down:\n",
            "\n",
            "1. **Identify and perform any multiplication or division first:**\n",
            "   The expression contains one multiplication: \\(4 \\times 5\\).\n",
            "   \\[\n",
            "   4 \\times 5 = 20\n",
            "   \\]\n",
            "   So, the expression now becomes:\n",
            "   \\[\n",
            "   6 + 20 - 1\n",
            "   \\]\n",
            "\n",
            "2. **Next, perform any addition or subtraction from left to right:**\n",
            "   First, we do the addition:\n",
            "   \\[\n",
            "   6 + 20 = 26\n",
            "   \\]\n",
            "   Now the expression is:\n",
            "   \\[\n",
            "   26 - 1\n",
            "   \\]\n",
            "   Finally, we do the subtraction:\n",
            "   \\[\n",
            "   26 - 1 = 25\n",
            "   \\]\n",
            "\n",
            "So, the final answer is:\n",
            "\\[\n",
            "25\n",
            "\\]\n"
          ]
        }
      ],
      "source": [
        "user_math_problem = \"6+4*5-1\"\n",
        "\n",
        "response = grok_client.chat.completions.create(\n",
        "  model=GROK_MODEL_NAME,\n",
        "  messages=[\n",
        "    {\"role\": \"system\",\n",
        "     \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": \"Solve {math_problem} step by step\".format(math_problem = user_math_problem)},\n",
        "  ],\n",
        "  temperature = 0.4\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DXRQ448Sj0I"
      },
      "source": [
        "#### Create Pydantic as Output Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Nhi7g-LPSpMO"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class MathSolution(BaseModel):\n",
        "    steps: str = Field(description=\"Thinking steps to solve the math problem.\")\n",
        "    final_answer: int = Field(description=\"Final answer of the math problem.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8X_Nf83Tg_L",
        "outputId": "27112a63-f82a-4cda-e9e6-4761f02090c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MathSolution(steps='1. Start with the expression: 6 + 4 * 5 - 1\\n2. According to the order of operations (PEMDAS/BODMAS), multiplication comes before addition and subtraction. So, we first calculate the multiplication: 4 * 5 = 20\\n3. Now the expression is: 6 + 20 - 1\\n4. Next, we perform the addition: 6 + 20 = 26\\n5. Finally, we perform the subtraction: 26 - 1 = 25\\n\\nThe final answer is 25.', final_answer=25)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = grok_client.beta.chat.completions.parse(\n",
        "    model=GROK_MODEL_NAME,\n",
        "    messages=[\n",
        "      {\"role\": \"system\",\n",
        "      \"content\": \"You are a helpful assistant.\"},\n",
        "      {\"role\": \"user\",\n",
        "      \"content\": \"Solve {math_problem} step by step\".format(math_problem = user_math_problem)},\n",
        "    ],\n",
        "    response_format =MathSolution,\n",
        "    temperature=0.4\n",
        "    )\n",
        "\n",
        "response.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f05Ld3iTXihq",
        "outputId": "54f5c09d-eb6b-46bc-cc80-6e4d2daaa9cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.choices[0].message.parsed.final_answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMnhvOMEXpdN",
        "outputId": "56bafcb4-396b-4270-ab28-43adbbbf25b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MathSolution2(steps=['1. **Identify and apply the order of operations**: According to the order of operations (PEMDAS/BODMAS), you should perform multiplication and division before addition and subtraction.', '2. **Perform the multiplication**: In the expression `6 + 4 * 5 - 1`, the multiplication is `4 * 5`.', '   - Calculation: `4 * 5 = 20`', '3. **Rewrite the expression with the result of multiplication**: The expression now becomes `6 + 20 - 1`.', '4. **Perform the addition**: Next, you add `6` and `20`.', '   - Calculation: `6 + 20 = 26`', '5. **Rewrite the expression with the result of addition**: The expression now becomes `26 - 1`.', '6. **Perform the subtraction**: Finally, you subtract `1` from `26`.', '   - Calculation: `26 - 1 = 25`', '7. **Final answer**: The result of `6 + 4 * 5 - 1` is `25`.'], final_answer=25)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class MathSolution2(BaseModel):\n",
        "    steps: List[str] = Field(description=\"Thinking steps to solve the math problem.\")\n",
        "    final_answer: int = Field(description=\"Final answer of the math problem.\")\n",
        "\n",
        "response = grok_client.beta.chat.completions.parse(\n",
        "    model=GROK_MODEL_NAME,\n",
        "    messages=[\n",
        "      {\"role\": \"system\",\n",
        "      \"content\": \"You are a helpful assistant.\"},\n",
        "      {\"role\": \"user\",\n",
        "      \"content\": \"Solve {math_problem} step by step\".format(math_problem = user_math_problem)},\n",
        "    ],\n",
        "    response_format = MathSolution2,\n",
        "    )\n",
        "\n",
        "response.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a5TXkZJX8rb",
        "outputId": "4d5a32d8-e064-48a5-938f-54544042ac35"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.choices[0].message.parsed.final_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfRUZIvEYnLf"
      },
      "source": [
        "### RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxvrKqauYyD8"
      },
      "source": [
        "#### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_gUOMQYZ07O"
      },
      "source": [
        "#### Search to bring context (a fake Search!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXTJPULkZ7jr",
        "outputId": "50e55dde-a3c1-4469-af55-4b63b7447642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected 5 random summaries:\n",
            "- Details how transformer models are applied to machine translation tasks, outperforming traditional RNN-based approaches.\n",
            "- Provides an introduction to RNNs, their structure, and how they handle sequential data with feedback connections.\n",
            "- Explores how transfer learning leverages pre-trained models to improve performance on related tasks with limited data.\n",
            "- Examines seq2seq models used in tasks like machine translation, including encoder-decoder architectures and attention.\n",
            "- Discusses word embeddings like Word2Vec and GloVe, their importance in capturing semantic relationships between words, and their applications.\n"
          ]
        }
      ],
      "source": [
        "def get_random_summaries(dataframe: pd.DataFrame, n: int = 5) -> list:\n",
        "    #Randomly chooses 'n' rows from the given DataFrame and returns a list of their summaries.\n",
        "    random_rows = dataframe.sample(n)\n",
        "    summaries_list = random_rows[\"summary\"].tolist()\n",
        "    return summaries_list\n",
        "\n",
        "random_summaries = get_random_summaries(df, n=5)\n",
        "print(\"Selected 5 random summaries:\")\n",
        "for s in random_summaries:\n",
        "    print(\"-\", s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ0naOa5aTsP"
      },
      "source": [
        "#### Build System and User Prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLzIhlfnfuAM",
        "outputId": "27b36b74-2d8d-499a-c088-20b3ce853580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "System Prompt:\n",
            "You are a helpful assistant.Answer user query using the provided context, if context is not related tell user.You should always answer user question, if context is not related answer by your own knowledge.\n",
            "\n",
            "User Prompt:\n",
            "User question: What does NLP stand for?\n",
            "Context:\n",
            "1. Details how transformer models are applied to machine translation tasks, outperforming traditional RNN-based approaches.\n",
            "2. Provides an introduction to RNNs, their structure, and how they handle sequential data with feedback connections.\n",
            "3. Explores how transfer learning leverages pre-trained models to improve performance on related tasks with limited data.\n",
            "4. Examines seq2seq models used in tasks like machine translation, including encoder-decoder architectures and attention.\n",
            "5. Discusses word embeddings like Word2Vec and GloVe, their importance in capturing semantic relationships between words, and their applications.\n",
            "End of context.\n"
          ]
        }
      ],
      "source": [
        "user_query = \"What does NLP stand for?\"\n",
        "\n",
        "def build_prompts(user_query: str, context_summaries: list) -> tuple:\n",
        "    system_prompt = \"\"\n",
        "    system_prompt += \"You are a helpful assistant.\"\n",
        "    system_prompt += \"Answer user query using the provided context, if context is not related tell user.\"\n",
        "    system_prompt += \"You should always answer user question, if context is not related answer by your own knowledge.\"\n",
        "\n",
        "\n",
        "\n",
        "    user_prompt = \"\"\n",
        "    user_prompt += f\"User question: {user_query}\\n\"\n",
        "    user_prompt += \"Context:\\n\"\n",
        "    for i, summary in enumerate(context_summaries, start=1):\n",
        "        user_prompt += f\"{i}. {summary}\\n\"\n",
        "\n",
        "    user_prompt += \"End of context.\"\n",
        "    return system_prompt, user_prompt\n",
        "\n",
        "# Example usage:\n",
        "system_prompt, user_prompt = build_prompts(user_query, random_summaries)\n",
        "print(\"\\nSystem Prompt:\")\n",
        "print(system_prompt)\n",
        "print(\"\\nUser Prompt:\")\n",
        "print(user_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4U4bcQqgGNv"
      },
      "source": [
        "#### RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "5U6k6xPogHhG",
        "outputId": "8ee1bc36-461c-48a2-9d64-53775bf7e9f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"NLP stands for Natural Language Processing. This context does not directly relate to the definition of NLP, so I've answered based on my own knowledge.\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = grok_client.chat.completions.create(\n",
        "    model=GROK_MODEL_NAME,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_prompt},\n",
        "      {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        "    temperature = 0.2\n",
        "    )\n",
        "\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsvWAhhiejHw"
      },
      "source": [
        "#### RAG with Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba9fGPwQgTyw",
        "outputId": "b8c7cea1-59a3-47a7-9915-91370b269649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "System Prompt:\n",
            "You are a helpful assistant.If the context is related to user query return True, else False.\n",
            "\n",
            "User Prompt:\n",
            "User question: What does NLP stand for?\n",
            "Context:\n",
            "1. Details how transformer models are applied to machine translation tasks, outperforming traditional RNN-based approaches.\n",
            "2. Provides an introduction to RNNs, their structure, and how they handle sequential data with feedback connections.\n",
            "3. Explores how transfer learning leverages pre-trained models to improve performance on related tasks with limited data.\n",
            "4. Examines seq2seq models used in tasks like machine translation, including encoder-decoder architectures and attention.\n",
            "5. Discusses word embeddings like Word2Vec and GloVe, their importance in capturing semantic relationships between words, and their applications.\n",
            "End of context.\n"
          ]
        }
      ],
      "source": [
        "def build_prompts(user_query: str, context_summaries: list) -> tuple:\n",
        "    system_prompt = \"\"\n",
        "    system_prompt += \"You are a helpful assistant.\"\n",
        "    system_prompt += \"If the context is related to user query return True, else False.\"\n",
        "\n",
        "    user_prompt = \"\"\n",
        "    user_prompt += f\"User question: {user_query}\\n\"\n",
        "    user_prompt += \"Context:\\n\"\n",
        "    for i, summary in enumerate(context_summaries, start=1):\n",
        "        user_prompt += f\"{i}. {summary}\\n\"\n",
        "\n",
        "    user_prompt += \"End of context.\"\n",
        "    return system_prompt, user_prompt\n",
        "\n",
        "# Example usage:\n",
        "system_prompt, user_prompt = build_prompts(user_query, random_summaries)\n",
        "print(\"\\nSystem Prompt:\")\n",
        "print(system_prompt)\n",
        "print(\"\\nUser Prompt:\")\n",
        "print(user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynghPmU-ek3n",
        "outputId": "a38636d4-60da-4b77-f4dd-67f88c1d68bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RelevancyCheck(explanation=\"The context provided focuses on specific aspects of natural language processing (NLP) such as transformer models, RNNs, transfer learning, seq2seq models, and word embeddings. However, it does not directly define what NLP stands for. The user's query specifically asks for the meaning of the acronym NLP, which is not explicitly answered in any of the context points.\", is_relevant=False)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class RelevancyCheck(BaseModel):\n",
        "    explanation: str = Field(description=\"Reasoning\")\n",
        "    is_relevant: bool\n",
        "\n",
        "response = grok_client.beta.chat.completions.parse(\n",
        "    model=GROK_MODEL_NAME,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_prompt},\n",
        "      {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ],\n",
        "    response_format = RelevancyCheck,\n",
        "    )\n",
        "\n",
        "response.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koyjBg-Y6FA7"
      },
      "source": [
        "## Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPUsnCis6OG8"
      },
      "source": [
        "### Install Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSJb9Frw6LpR",
        "outputId": "5bd45057-d703-412e-a93e-ea27f4c9f11c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWd2qYO76hX_"
      },
      "source": [
        "### Create a ChatModel client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Twrm-E376gov"
      },
      "outputs": [],
      "source": [
        "PROVIDER_BASE_URL = \"https://api.together.xyz/v1\"\n",
        "MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    base_url=GROK_BASE_URL,\n",
        "    api_key=os.getenv(\"GROK_API_KEY\"),\n",
        "    model=GROK_MODEL_NAME,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfqUhfhL608v"
      },
      "source": [
        "### A simple LLM call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULB3327U6zpg",
        "outputId": "9f418b12-2d47-4e2c-a412-17281c1b5263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'text_tokens': 10, 'image_tokens': 0}}, 'model_name': 'grok-2-1212', 'system_fingerprint': 'fp_149a247ffa', 'finish_reason': 'stop', 'logprobs': None}, id='run-056d33ad-1a8d-4870-a97c-d34b63522f2d-0', usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"Hello, world!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSYkw4rk67Zj",
        "outputId": "bbdb497c-5aa2-4242-db73-b08bac423260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am Grok, created by xAI. I'm an AI designed to provide helpful and truthful answers, often with a dash of outside perspective on humanity. Think of me as a friendly, cosmic guide, here to assist and enlighten. What's on your mind?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"Who are you?\").content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXg-pPlE7KUZ"
      },
      "source": [
        "### Structured Output using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PIlwkD27Ktt",
        "outputId": "a248be1b-82b6-48a4-f18a-fc3010836c7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x32e886a90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x32cccf950>, root_client=<openai.OpenAI object at 0x32c036f50>, root_async_client=<openai.AsyncOpenAI object at 0x32c6ff910>, model_name='grok-2-1212', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.x.ai/v1'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Greeting', 'description': '', 'parameters': {'properties': {'sentence': {'type': 'string'}, 'possible_negative_interpretation': {'type': 'string'}}, 'required': ['sentence', 'possible_negative_interpretation'], 'type': 'object'}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'Greeting'}}}, config={}, config_factories=[])\n",
              "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Greeting'>])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class Greeting(BaseModel):\n",
        "    sentence: str\n",
        "    possible_negative_interpretation: str\n",
        "\n",
        "model_hello_world = model.with_structured_output(Greeting)\n",
        "model_hello_world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "invHnU-H7QV0",
        "outputId": "4abfb875-9ac6-41d7-a0ef-9cc96be9f081"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Greeting(sentence='Hello how are you', possible_negative_interpretation='None')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_hello_world.invoke(\"Hello how are you\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEv3fBA37UL6"
      },
      "source": [
        "### Chain of Thought using Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "EYR4llun7Uzj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x32e886a90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x32cccf950>, root_client=<openai.OpenAI object at 0x32c036f50>, root_async_client=<openai.AsyncOpenAI object at 0x32c6ff910>, model_name='grok-2-1212', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.x.ai/v1'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'MathReasoning', 'description': '', 'parameters': {'properties': {'steps': {'description': 'Reasoning Steps to get to final Result', 'items': {'properties': {'explanation': {'type': 'string'}, 'output': {'default': 'rewrote question', 'type': 'string'}}, 'required': ['explanation'], 'type': 'object'}, 'type': 'array'}, 'final_answer': {'description': 'Final Result of math expression.', 'type': 'integer'}}, 'required': ['steps', 'final_answer'], 'type': 'object'}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'MathReasoning'}}}, config={}, config_factories=[])\n",
              "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.MathReasoning'>])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class Step(BaseModel):\n",
        "    explanation: str\n",
        "    output: str = Field(\"rewrote question\")\n",
        "\n",
        "class MathReasoning(BaseModel):\n",
        "    steps: List[Step] = Field(description=\"Reasoning Steps to get to final Result\")\n",
        "    final_answer: int = Field(description=\"Final Result of math expression.\")\n",
        "    \n",
        "math_model = model.with_structured_output(MathReasoning)\n",
        "math_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH3Rezmg7Xfq",
        "outputId": "082fa1ba-88a4-4004-bcc0-a9628fe2bced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['expression'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Calculate the following math expression step by step.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['expression'], input_types={}, partial_variables={}, template='This is the problem: {expression}'), additional_kwargs={})])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "math_system_template = \"Calculate the following math expression step by step.\"\n",
        "\n",
        "math_prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", math_system_template), (\"user\", \"This is the problem: {expression}\")]\n",
        ")\n",
        "math_prompt_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Calculate the following math expression step by step.', additional_kwargs={}, response_metadata={}), HumanMessage(content='This is the problem: 25 * 2 + 10', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math_test_prompt = math_prompt_template.invoke({\"expression\": \"25 * 2 + 10\"})\n",
        "math_test_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pa48zFv7uP-",
        "outputId": "71fd3ca5-7f82-40b8-9e1a-62a1edd5b037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "steps=[Step(explanation='First, we need to perform the multiplication operation. We multiply 25 by 2.', output='50'), Step(explanation='Next, we add 10 to the result of the multiplication.', output='60')] final_answer=60\n"
          ]
        }
      ],
      "source": [
        "print(math_model.invoke(math_test_prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk6VCzD673nA",
        "outputId": "571bb626-de5e-4c18-9495-4dca8b824759"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MathReasoning(steps=[Step(explanation='First, we need to multiply 25 by 2. This gives us 50.', output='50'), Step(explanation='Next, we add 10 to the result of the multiplication. 50 + 10 equals 60.', output='60')], final_answer=60)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math_chain = math_prompt_template | math_model\n",
        "math_results = math_chain.invoke({\"expression\": \"25 * 2 + 10\"})\n",
        "math_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pweI0GLv792t",
        "outputId": "e5f1ab40-7105-48e4-89d1-cf04308d77bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "math_results.final_answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w1GEWro8NXn"
      },
      "source": [
        "### RAG + Structured Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "PL-EvhBr8Nk5"
      },
      "outputs": [],
      "source": [
        "class QueryGenerator(BaseModel):\n",
        "    queries: List[str] = Field(description=\"List of detailed questions that can be answered using the provided summaries\")\n",
        "\n",
        "rag_model = model.with_structured_output(QueryGenerator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wPQ6Xuq8dn_",
        "outputId": "782bdd00-7815-4e1b-f531-5bc47728a19f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='You are given a context and a question.\\nYour task is to generate 3 specific user queries similar but with diversity of user question for context search that can be answered using these context.\\nContext: {context}\\nUser Question: {question}\\n'), additional_kwargs={})])\n",
              "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x32e886a90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x32cccf950>, root_client=<openai.OpenAI object at 0x32c036f50>, root_async_client=<openai.AsyncOpenAI object at 0x32c6ff910>, model_name='grok-2-1212', model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.x.ai/v1'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'QueryGenerator', 'description': '', 'parameters': {'properties': {'queries': {'description': 'List of detailed questions that can be answered using the provided summaries', 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['queries'], 'type': 'object'}}}], 'parallel_tool_calls': False, 'tool_choice': {'type': 'function', 'function': {'name': 'QueryGenerator'}}}, config={}, config_factories=[])\n",
              "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.QueryGenerator'>])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_prompt_template = ChatPromptTemplate.from_template(\"\"\"You are given a context and a question.\n",
        "Your task is to generate 3 specific user queries similar but with diversity of user question for context search that can be answered using these context.\n",
        "Context: {context}\n",
        "User Question: {question}\n",
        "\"\"\")\n",
        "\n",
        "rag_chain = rag_prompt_template | rag_model\n",
        "rag_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywtA9Iv-8itt",
        "outputId": "c16a872a-3b03-41bf-b59b-1d18ae7d7899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "QueryGenerator(queries=['How is deep learning used for diagnostics in healthcare?', 'What role does deep learning play in personalized medicine?', 'Can you list specific deep learning applications in the healthcare sector?'])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "context = \"Examines the applications of deep learning techniques in the healthcare industry, including diagnostics and personalized medicine.\"\n",
        "question = \"What are the applications of deep learning in healthcare?\"\n",
        "\n",
        "rag_chain.invoke({\"context\": context, \"question\": question})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
